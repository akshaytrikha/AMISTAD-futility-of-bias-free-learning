<!DOCTYPE html>
<html>
<head>
  <title>Futility of Bias-Free Learning and Search - AMISTAD Lab</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
  <link rel="stylesheet" type="text/css" href="main.css">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
  <!-- Google Analytics setup -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-83215098-1', 'auto');
    ga('send', 'pageview');
  </script>
  <!-- MathJax Setup -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
<div div style="margin: auto;" class="main-page-box">
  <!-- AMISTAD x NSF x HMC -->
  <div style="text-align: center; margin-top: 5%; margin-bottom: 1%;">
    <img src="./images/header-logos.png" alt="AMISTAD Logo" class="" style="width: 99.5%;">
  </div>

  <h1>The Futility of Bias-Free Learning and Search</h1>
  <h2 class="subtitle">2019</h2>
  <h3>&#127820; Overview &#127820;</h3>
  <p>
    Imagine you are on a routine grocery shopping trip and plan to buy some bananas. You know that the store carries both good and bad bananas which you must search through. There are multiple ways you can go about your search. <br><br>

    You could: <br>
    1) randomly pick any ten bananas available on the shelf (unbiased search) <br>
    2) Only pick those bananas that are neither underripe nor overripe (biased search) <br><br>

    We mathematically prove that for a machine, the proportion of good bananas retrieved in its biased search is greater than the same proportion in an unbiased search; it was given prior knowledge about tasty bananas. <br><br>

    We further prove that an algorothm cannot be simulatenously biased towards all types of bananas (underripe, overripe, perfect).
  </p>

  <!-- Definitions -->
  <h3>Key Definitions</h3>
  <h4>Bias</h4>
  <p>
    Statistical bias is when the expected value of a parameter differs from its true value.<br><br>

    We define bias to be a measure of how different the performance of one distrbution is to that of a uniform distribution. <br><br>

    Given a: <br>
      &bull; \(k\)-sized fixed target \(t\)<br>
      &bull; distribution over information resources \(\mathcal{D}\) <br>
      &bull; search algorithm \(\bar{P_f}\) <br>
      &bull; performance of uniform random sampling \(p\) <br>

    $$\text{Bias}(\mathcal{D},t) = \mathbb{E}_{\mathcal{D}}\big{|} t^{\top} \bar{P}_F \big{|} - p$$

    <span style="font-weight:400;">Note:</span> algorithmic bias has very little to do with unfortunate human biases (racial, xenophobic, etc.). Our version of algorithmic bias is <span style="font-style:italic;">strictly</span>
    defined in the domain of mathematics, and human examples of it include picking the simplest solution from a set, and choosing a particular
    type of learning algorithm to solve a problem.
  </p>
  <h4>Target Divergence</h4>
  <p>
    What does algorithmic bias look like? Target divergence is a geometric interpretation of it which measures the angle between the target vector \(t\) and the averaged \(|\Omega|\)-length simplex vector \(P_f\) using cosine similarity.
  </p>
  <div>
    <div style="margin-bottom: 0%;">
      <div style="display:inline-block;">
        <img src="./images/target-divergence-1.png" alt="Target Divergence 1" class="target-divergence-diagram">
      </div>
      <div style="display:inline-block;">
        <img src="./images/target-divergence-2.png" alt="Target Divergence 2" class="target-divergence-diagram">
      </div>
    </div>
    <div>
      <div style="display:inline-block; margin-top: 4%;">
        <img src="./images/target-divergence-3.png" alt="Target Divergence 3" class="target-divergence-diagram">
      </div>
    </div>
  </div>

  <!-- Important Theorems -->
  <h3>Results</h3>
  <h4>Improbability of Favourable Information Resources</h4>
  <p>
    Let \(F\) be a random variable such that \(F\) ~ \(\mathcal{D}\) and let \(q(t,F)\) be the expected per-query probability of success for algorithm \(\mathcal{A}\) on search problem \((\Omega, t, F)\). Then for any \(q_{min}\) \(\in\) [0,1],

    $$\mathbb{P}(q(t,F) \geq q_{min}) \leq \frac{p + \text{Bias}(\mathcal{D}, t)}{q_{min}}$$

    Using the per-query probability of success from <a href="https://arxiv.org/pdf/1609.08913.pdf">The Famine of Forte</a>, we bound the probability that an algorithm is successful, this time in terms of its bias.
    This shows that an algorithm cannot perform better than uniform random sampling of the search space if the bias term is 0.
  </p>
  <h4>Conservation of Bias over Distributions</h4>
  <p>
    Let \(F\) be a random variable such that \(F\) ~ \(\mathcal{D}\) and let \(q(t,F)\) be the expected per-query probability of success for algorithm \(\mathcal{A}\) on search problem \((\Omega, t, F)\). Then for any \(q_{min}\) \(\in\) [0,1],

    $$\sum_{t \in \tau_{k}} \int_{\mathcal{P}} \text{Bias}(\mathcal{D},t) d\mathcal{D} = 0$$

    Similar to conservation laws for energy and mass in physics, we show that bias is a conserved quantity. <br><br>
    An algorithm can have positive bias on a particular target, but this implies it also has negative bias on some other targets in the search space.
    We show that the total bias an algorithm has is 0, thus bias encodes tradeoffs and we must choose which targets we want to be biased towards. <br><br>

    This further means that an algorithm cannot be biased towards all possible trargets such that it would perform well on all problems.
  </p>
  <h4>Futility of Bias-Free Search</h4>
  <p>
    If \( \text{Bias}(\mathcal{D},t) = 0 \) then,

    $$ \mathbb{P}(\omega \in t; \mathcal{A}) = p $$

    Our bias quantity essentially captures how much more likely an algorithm is to find an acceptable model to fit some data than by picking a model at random.
    Thus when an algorithm has no bias, the probability it will find an accepatable model is equal to the probability of it uniformly randomly sampling from a set of possible models.
  </p>

  <!-- Authors and Headshots -->
  <h3>Authors</h3>
  <div>
    <div style="margin-bottom: 3%;">
      <div style="display:inline-block;">
        <a href="https://www.linkedin.com/in/jonathan-hayase-5ab849128/">
          <img src="./images/jonathan.jpg" alt="Jonathan Hayase" class="headshot" style="padding-left: 0;">
        </a>
        <a href="https://www.linkedin.com/in/jonathan-hayase-5ab849128/" class="text-link">
          <p style="text-align:center; margin: 0;">Jonathan Hayase</p>
        </a>
      </div>
      <div style="display:inline-block;">
        <a href="https://www.linkedin.com/in/julius-lauw-882652139/">
          <img src="./images/julius.jpg" alt="Julius Lauw" class="headshot">
        </a>
        <a href="https://www.linkedin.com/in/julius-lauw-882652139/" class="text-link">
          <p style="text-align:center; margin: 0;">Julius Lauw</p>
        </a>
      </div>
      <div style="display:inline-block;">
        <a href="https://www.linkedin.com/in/dominique-macias/">
          <img src="./images/dom.jpg" alt="Dominique Macias" class="headshot" style="padding-right: 0;">
        </a>
        <a href="https://www.linkedin.com/in/dominique-macias/" class="text-link">
          <p style="text-align:center; margin: 0;">Dominique Macias</p>
        </a>
      </div>
    </div>
    <div>
      <div style="display:inline-block;">
        <a href="https://www.linkedin.com/in/akshay-trikha">
          <img src="./images/akshay.jpg" alt="Akshay Trikha" class="headshot" style="padding-left: 0;">
        </a>
        <a href="https://www.linkedin.com/in/akshay-trikha" class="text-link">
          <p style="text-align:center; margin: 0;">Akshay Trikha</p>
        </a>
      </div>
      <div style="display:inline-block;">
        <a href="https://www.linkedin.com/in/julia-vendemiatti-645a5613a/">
          <img src="./images/julia.jpg" alt="Julia Vendemiatti" class="headshot">
        </a>
        <a href="https://www.linkedin.com/in/julia-vendemiatti-645a5613a/" class="text-link">
          <p style="text-align:center; margin: 0;">Julia Vendemiatti</p>
        </a>
      </div>
      <div style="display:inline-block;">
        <a href="mailto:gmontanez@g.hmc.edu">
          <img src="./images/prof-george.png" alt="George Monta&ntilde;ez" class="headshot" style="padding-right: 0;">
        </a>
        <a href="mailto:gmontanez@g.hmc.edu" class="text-link">
          <p style="text-align:center; margin: 0;">George Monta&ntilde;ez</p>
        </a>
      </div>
    </div>
  </div>

  <!-- Thank you(s) -->
  <h3>Acknowledgements</h3>
  <p>
    We'd like to thank our loving families and supportive friends, Professor George for his guidance,  and the Walter Bradley Center for Natural and Artificial Intelligence.
  <p>
  <!-- Citations -->
  <h3>References</h3>
  <p>
    &bull; Monta&ntildeez, G.D., Hayase, J., Lauw, J., Macias, D., Trikha, A., Vendemiatti, J. :The Futility of Bias-Free Learning and Search. arXiv e-prints arXiv:1907.06010(Jul 2019)<br><br>
    &bull; Monta&ntildeez, G.D. :The famine of forte: Few search problems greatly favor your algorithm.  In: 2017 IEEE International Conference on Systems, Man, and Cybernetics(SMC). pp. 477-482. IEEE (2017)<br><br>
    &bull; Wolpert, D.H., Macready, W.G.: No free lunch theorems for optimization. Trans.Evol. Comp1(1), 67-82 (Apr 1997)<br><br>
    &bull; Mitchell, T.D.: The need for biases in learning generalizations. In: Rutgers University: CBM-TR-117 (1980)<br><br>
  <p>

  <div class="bottom-nav">
    <a href="https://www.cs.hmc.edu/~montanez/amistad.html">Home</a> <!-- TODO: update to .html link-->
    <a href="https://www.cs.hmc.edu/~montanez/publications.html">Publications</a> <!-- TODO: update to .html link-->
    <a href="https://www.linkedin.com/in/georgemontanez">LinkedIn</a>
    <a href="https://www.dropbox.com/s/emtdx2qmjxz14ha/cv.pdf?dl=0">CV</a>
    <a href="https://github.com/george-montanez">GitHub</a>
  </div>
</body>
</html>
