<!DOCTYPE html>
<html>
<head>
  <title>Futility of Bias-Free Learning and Search - AMISTAD Lab</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=3.0">
  <meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
  <meta id="meta" name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="stylesheet" type="text/css" href="main.css">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
  <!-- Google Analytics setup -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-83215098-1', 'auto');
    ga('send', 'pageview');
  </script>
  <!-- MathJax Setup -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
<!-- AMISTAD x NSF x HMC -->
<div class="title">
  <div class="logo-column" style="width:100%;">
    <img class="amistad-logo" src="./images/amistad-logo.png" />
</div>

<div>
  <h1>The Search Framework</h1>
  <div style="margin: auto;" class="main-page-box">
    <h3>Overview</h3>
    <p>
      <!-- Using a framework that casts most machine learning problems as search problems, we quantified bias towards a "target" (for example, a model that approximates a "true distribution" of variables). The "bias" quantity we defined basically captures how much more likely an algorithm is to find an acceptable model than picking a model at random. Then, under this framework, we proved that no algorithm can have bias towards any given target set. Additionally, we proved that bias is a conserved quantity for algorithms. Thus, to the degree that an algorithm is more biased towards a particular target, is to the degree that it is biased against other targets. This also serves as a generalization of the "No Free Lunch" Theorems, because we show that no algorithm can be favorably biased towards many distinct targets simultaneously. Thus bias encodes trade-offs: the more bias, the better we can perform for a fixed problem, but the worse we perform on all other problems. -->
      A search problem is represented as a tuple \((\Omega, T, F)\): <br>
        &bull; \(\Omega\): finite search space<br>
        &bull; \(T\): target subset of elements in search space<br>
        &bull; \(F\): external information resrouce<br><br>

      <span style="font-weight:400;">Note:</span> The external information resource is a purposefully general concept that helps a leanring algorithm make guesses about the search space. <br>
      In more technical words, it's a binary string that provides initialization information for the search and evaluates points in \( \Omega \), acting as an oracle that guides the search process.
      For example, this could manifest as training data or loss functions. <br><br>

      Given a search problem, a history of elements already examined, and information resource evaluations, an algorithmic search is a process that decides how to query elements of \( \Omega \).
    <div>
      <div style="margin-bottom: 0%;">
        <div style="display:inline-block;">
          <img src="./images/jellyfish-2.jpg" alt="Target Divergence 1" class="jellyfish-diagram">
          <p style="text-align:center; margin-top: 1%; margin-bottom:0.5em;">
            <span style="font-weight:400;">Figure:</span>
            As a black-box optimization algorithm samples from \(\Omega\), it produces an associated probability distribution \(P_i\) based on the search history.
            When a sample \( \omega_k \) corresponding to location \(k\) in \(\Omega\) is evaluated using the external information resource \(F\), the tuple (\(\omega_k\), \(F(\omega_k)\)) is added to the search history.
          </p>
        </div>
      </div>
    </div>
    <p>
      As was shown in <a href="http://www.cs.cmu.edu/~gmontane/montanez_dissertation.pdf">Why Machine Learning Works</a>,
      this framework applies to classification, regression, clustering, optimization, reinforcement learning, and the general machine learning problems considered in Vapnik's <a href="https://www.math.arizona.edu/~hzhang/math574m/Read/vapnik.pdf">learning framework</a>.
    </p>
    <h3>Measuring Performance</h3>
    <p>
      <span style="font-weight:400;">Big Picture: </span>We need a way to fairly measure the performance of an optimizaiton algorithm. <br><br>

      The total probability of success for an algorithm is affected by the number of sampling steps, which are in turn affected by the particular algorithm used and the particular run of that algorithm.
      \(q(T,F)\) provides a normalized measure of performance compared to an algorithm's total probability of success.<br><br>

      Given a: <br>
        &bull; target \(T\) <br>
        &bull; information resource \(F\) <br>
        &bull; sequence of probability distributions over the search space \(\tilde{P}\)<br>
        &bull; distribution at timestep i \(P_i\)<br>
        &bull; search history \(H\) <br>
        &bull; sample from target \(\omega\)


      $$q(T,F) = \mathbb{E}_{\tilde{P}, H} \Bigg[ \frac{1}{|\tilde{P}|} \sum_{i=1}^{|\tilde{P}|} P_i(\omega \in T) \Bigg| F \Bigg]$$

      The number of queries during a search is equal to the length of the probability distribution sequence,  \(|\tilde{P}|\).
      The outer expectation accounts (\(\mathbb{E}_{\bar{P},H} \))for stochastic differences in multiple runs of the algorithm,
      whereas the inner quantity is equivalent to the expected probability of success for a uniformly sampled time step of a given run. <br><br>

      Furthermore, the per-query probability of success naturally accounts for sampling procedures that may involve repeatedly sampling the same points in the search space,
      as is the case with <a href="https://deepblue.lib.umich.edu/bitstream/handle/2027.42/46947/10994_2005_Article_422926.pdf">genetic algorithms</a>.
      This allows the measure to deftly handle search algorithms that manage trade-offs between exploration and exploitation. <br><br>
    </p>
  </div>
  <div class="bottom-nav">
    <a href="index.html">Home</a>
    <a href="publications.html">Publications</a>
    <a href="https://www.linkedin.com/in/georgemontanez">LinkedIn</a>
    <a href="https://www.dropbox.com/s/emtdx2qmjxz14ha/cv.pdf?dl=0">CV</a>
    <a href="https://github.com/george-montanez">GitHub</a>
  </div>
</div>
</body>
</html>
